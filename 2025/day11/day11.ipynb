{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467a325a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "758"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#part 1\n",
    "def parse_graph(lines):\n",
    "    graph = {}\n",
    "    for line in lines:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        name, targets = line.split(\":\")\n",
    "        name = name.strip()\n",
    "        targets = targets.strip().split()\n",
    "        graph[name] = targets\n",
    "    return graph\n",
    "\n",
    "def all_paths(graph, start, end):\n",
    "    paths = []\n",
    "    stack = [(start, [start])]\n",
    "    while stack:\n",
    "        node, path = stack.pop()\n",
    "        if node == end:\n",
    "            paths.append(path)\n",
    "            continue\n",
    "        if node not in graph:\n",
    "            continue\n",
    "        for nxt in graph[node]:\n",
    "            if nxt not in path:\n",
    "                stack.append((nxt, path + [nxt]))\n",
    "    return paths\n",
    "\n",
    "\n",
    "with open('input.txt','r') as f:\n",
    "    inputs=[line.strip() for line in f.readlines()]\n",
    "\n",
    "graph = parse_graph(inputs)\n",
    "paths = all_paths(graph, \"you\", \"out\")\n",
    "\n",
    "len(paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fd7a8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m     inputs\u001b[38;5;241m=\u001b[39m[line\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mreadlines()]\n\u001b[0;32m     34\u001b[0m graph \u001b[38;5;241m=\u001b[39m parse_graph(inputs)\n\u001b[1;32m---> 35\u001b[0m paths \u001b[38;5;241m=\u001b[39m \u001b[43mall_paths_with_required\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msvr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mout\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdac\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal paths:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(paths))\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m paths:\n",
      "Cell \u001b[1;32mIn[3], line 26\u001b[0m, in \u001b[0;36mall_paths_with_required\u001b[1;34m(graph, start, end, required_nodes)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m nxt \u001b[38;5;129;01min\u001b[39;00m graph[node]:\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m nxt \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m path:\n\u001b[1;32m---> 26\u001b[0m             new_required \u001b[38;5;241m=\u001b[39m seen_required \u001b[38;5;241m|\u001b[39m (\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnxt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrequired\u001b[49m)\n\u001b[0;32m     27\u001b[0m             stack\u001b[38;5;241m.\u001b[39mappend((nxt, path \u001b[38;5;241m+\u001b[39m [nxt], new_required))\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m paths\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#not working part2\n",
    "def parse_graph(lines):\n",
    "    graph = {}\n",
    "    for line in lines:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        name, targets = line.split(\":\")\n",
    "        name = name.strip()\n",
    "        targets = targets.strip().split()\n",
    "        graph[name] = targets\n",
    "    return graph\n",
    "\n",
    "def all_paths_with_required(graph, start, end, required_nodes):\n",
    "    required = set(required_nodes)\n",
    "    paths = []\n",
    "    stack = [(start, [start], set([start]) & required)]\n",
    "    while stack:\n",
    "        node, path, seen_required = stack.pop()\n",
    "        if node == end:\n",
    "            if seen_required == required:\n",
    "                paths.append(path)\n",
    "            continue\n",
    "        if node not in graph:\n",
    "            continue\n",
    "        for nxt in graph[node]:\n",
    "            if nxt not in path:\n",
    "                new_required = seen_required | (set([nxt]) & required)\n",
    "                stack.append((nxt, path + [nxt], new_required))\n",
    "    return paths\n",
    "\n",
    "with open('input.txt','r') as f:\n",
    "    inputs=[line.strip() for line in f.readlines()]\n",
    "\n",
    "graph = parse_graph(inputs)\n",
    "paths = all_paths_with_required(graph, \"svr\", \"out\", ['fft','dac'])\n",
    "\n",
    "print(\"Total paths:\", len(paths))\n",
    "for p in paths:\n",
    "    print(\" -> \".join(p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ba3fcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m     inputs\u001b[38;5;241m=\u001b[39m[line\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mreadlines()]\n\u001b[0;32m     66\u001b[0m graph \u001b[38;5;241m=\u001b[39m parse_graph(inputs)\n\u001b[1;32m---> 67\u001b[0m paths \u001b[38;5;241m=\u001b[39m \u001b[43mall_paths_with_required_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msvr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mout\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdac\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal paths:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(paths))\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m paths:\n",
      "Cell \u001b[1;32mIn[3], line 51\u001b[0m, in \u001b[0;36mall_paths_with_required_fast\u001b[1;34m(graph, start, end, required_nodes)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nxt \u001b[38;5;129;01min\u001b[39;00m path:   \u001b[38;5;66;03m# prevent cycles\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnxt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreachable_to_end\u001b[49m:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# pruning: cannot reach end from here\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nxt \u001b[38;5;129;01min\u001b[39;00m required:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#not working part2\n",
    "def parse_graph(lines):\n",
    "    graph = {}\n",
    "    for line in lines:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        name, targets = line.split(\":\")\n",
    "        name = name.strip()\n",
    "        targets = targets.strip().split()\n",
    "        graph[name] = targets\n",
    "    return graph\n",
    "\n",
    "\n",
    "def all_paths_with_required_fast(graph, start, end, required_nodes):\n",
    "    required = set(required_nodes)\n",
    "\n",
    "    reverse = {node: [] for node in graph}\n",
    "    for src, outs in graph.items():\n",
    "        for dst in outs:\n",
    "            reverse.setdefault(dst, []).append(src)\n",
    "\n",
    "    reachable_to_end = set([end])\n",
    "    queue = [end]\n",
    "    while queue:\n",
    "        cur = queue.pop()\n",
    "        for prev in reverse.get(cur, []):\n",
    "            if prev not in reachable_to_end:\n",
    "                reachable_to_end.add(prev)\n",
    "                queue.append(prev)\n",
    "\n",
    "    paths = []\n",
    "    stack = [(start, (start,), frozenset([start]) & required)]\n",
    "\n",
    "    while stack:\n",
    "        node, path, seen_required = stack.pop()\n",
    "\n",
    "        if node == end:\n",
    "            if seen_required == required:\n",
    "                paths.append(path)\n",
    "            continue\n",
    "\n",
    "        if node not in graph:\n",
    "            continue\n",
    "        if node not in reachable_to_end:\n",
    "            continue\n",
    "\n",
    "        outs = graph[node]\n",
    "        for nxt in outs:\n",
    "            if nxt in path:   # prevent cycles\n",
    "                continue\n",
    "\n",
    "            if nxt not in reachable_to_end:\n",
    "                continue  # pruning: cannot reach end from here\n",
    "\n",
    "            if nxt in required:\n",
    "                new_seen = seen_required | {nxt}\n",
    "            else:\n",
    "                new_seen = seen_required\n",
    "\n",
    "            stack.append((nxt, path + (nxt,), new_seen))\n",
    "\n",
    "    return paths\n",
    "\n",
    "with open('input.txt','r') as f:\n",
    "    inputs=[line.strip() for line in f.readlines()]\n",
    "\n",
    "graph = parse_graph(inputs)\n",
    "paths = all_paths_with_required_fast(graph, \"svr\", \"out\", ['fft','dac'])\n",
    "\n",
    "print(\"Total paths:\", len(paths))\n",
    "for p in paths:\n",
    "    print(\" -> \".join(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0f602e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not working part2\n",
    "def parse_graph(lines):\n",
    "    graph = {}\n",
    "    for line in lines:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        name, targets = line.split(\":\")\n",
    "        name = name.strip()\n",
    "        targets = targets.strip().split()\n",
    "        graph[name] = targets\n",
    "    return graph\n",
    "\n",
    "\n",
    "def count_paths_required(graph, start, end, required_nodes):\n",
    "    # -----------------------------------------------------\n",
    "    # Step 1 — Map nodes to integer IDs (fast lookup)\n",
    "    nodes = list(graph.keys())\n",
    "    for outs in graph.values():\n",
    "        for node in outs:\n",
    "            if node not in graph:\n",
    "                nodes.append(node)\n",
    "\n",
    "    nodes = sorted(set(nodes))\n",
    "    id_map = {name: i for i, name in enumerate(nodes)}\n",
    "    n = len(nodes)\n",
    "\n",
    "    start_id = id_map[start]\n",
    "    end_id = id_map[end]\n",
    "\n",
    "    # Build adjacency list of IDs\n",
    "    adj = [[] for _ in range(n)]\n",
    "    for src, outs in graph.items():\n",
    "        s = id_map[src]\n",
    "        for o in outs:\n",
    "            adj[s].append(id_map[o])\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Step 2 — Precompute reachability to \"end\"\n",
    "    rev = [[] for _ in range(n)]\n",
    "    for s in range(n):\n",
    "        for o in adj[s]:\n",
    "            rev[o].append(s)\n",
    "\n",
    "    reachable = [False] * n\n",
    "    reachable[end_id] = True\n",
    "    stack = [end_id]\n",
    "\n",
    "    while stack:\n",
    "        cur = stack.pop()\n",
    "        for prev in rev[cur]:\n",
    "            if not reachable[prev]:\n",
    "                reachable[prev] = True\n",
    "                stack.append(prev)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Step 3 — Build required bitmask\n",
    "    required_nodes = [r for r in required_nodes if r in id_map]\n",
    "    req_bits = {id_map[name]: (1 << i) for i, name in enumerate(required_nodes)}\n",
    "    required_full_mask = (1 << len(required_nodes)) - 1\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Step 4 — DFS + Memoization (DP)\n",
    "    # visited_mask tracks visited nodes to avoid cycles\n",
    "    from functools import lru_cache\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def dfs(node_id, req_mask, visited_mask):\n",
    "        # prune: cannot reach end from here\n",
    "        if not reachable[node_id]:\n",
    "            return 0\n",
    "\n",
    "        # reached end: check if all required nodes were hit\n",
    "        if node_id == end_id:\n",
    "            return 1 if req_mask == required_full_mask else 0\n",
    "\n",
    "        total = 0\n",
    "        for nxt in adj[node_id]:\n",
    "\n",
    "            bit = 1 << nxt\n",
    "            if visited_mask & bit:\n",
    "                continue  # cycle prevention\n",
    "\n",
    "            new_req_mask = req_mask\n",
    "            if nxt in req_bits:\n",
    "                new_req_mask |= req_bits[nxt]\n",
    "\n",
    "            total += dfs(nxt, new_req_mask, visited_mask | bit)\n",
    "\n",
    "        return total\n",
    "\n",
    "    # initial state\n",
    "    start_req_mask = req_bits[start_id] if start_id in req_bits else 0\n",
    "    start_visited = 1 << start_id\n",
    "\n",
    "    return dfs(start_id, start_req_mask, start_visited)\n",
    "\n",
    "with open(\"input.txt\") as f:\n",
    "    inputs = [line.strip() for line in f]\n",
    "graph = parse_graph(inputs)\n",
    "count = count_paths_required(graph, \"svr\", \"out\", [\"fft\", \"dac\"])\n",
    "print(\"Total matching paths:\", count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5094d0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490695961032000\n"
     ]
    }
   ],
   "source": [
    "#part2 working\n",
    "#SCC Condensation → DAG → Bitmask DP for Required-Node Path Counting\n",
    "#determinstic\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "def parse_graph(lines):\n",
    "    graph = {}\n",
    "    for line in lines:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        name, targets = line.split(\":\")\n",
    "        name = name.strip()\n",
    "        targets = targets.strip().split()\n",
    "        graph[name] = targets\n",
    "    return graph\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Kosaraju SCC (Strongly Connected Components)\n",
    "def compute_scc(graph):\n",
    "    # Ensure all nodes appear in graph by adding missing keys\n",
    "    missing = set()\n",
    "    for outs in graph.values():\n",
    "        for v in outs:\n",
    "            if v not in graph:\n",
    "                missing.add(v)\n",
    "\n",
    "    # Now safely add missing nodes\n",
    "    for v in missing:\n",
    "        graph[v] = []\n",
    "\n",
    "    nodes = list(graph.keys())\n",
    "\n",
    "    # -------------------------\n",
    "    # First DFS (postorder)\n",
    "    visited = set()\n",
    "    order = []\n",
    "\n",
    "    def dfs1(u):\n",
    "        visited.add(u)\n",
    "        for v in graph[u]:\n",
    "            if v not in visited:\n",
    "                dfs1(v)\n",
    "        order.append(u)\n",
    "\n",
    "    for node in nodes:\n",
    "        if node not in visited:\n",
    "            dfs1(node)\n",
    "\n",
    "    # -------------------------\n",
    "    # Reverse graph\n",
    "    rev = defaultdict(list)\n",
    "    for u in graph:\n",
    "        for v in graph[u]:\n",
    "            rev[v].append(u)\n",
    "\n",
    "    # -------------------------\n",
    "    # Second DFS (component assign)\n",
    "    comp_id = {}\n",
    "    current_comp = 0\n",
    "\n",
    "    def dfs2(u):\n",
    "        comp_id[u] = current_comp\n",
    "        for v in rev[u]:\n",
    "            if v not in comp_id:\n",
    "                dfs2(v)\n",
    "\n",
    "    for u in reversed(order):\n",
    "        if u not in comp_id:\n",
    "            dfs2(u)\n",
    "            current_comp += 1\n",
    "\n",
    "    return comp_id, current_comp\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Build condensed DAG\n",
    "def build_condensed_dag(graph, comp_id, num_comps):\n",
    "    dag = [set() for _ in range(num_comps)]\n",
    "    comp_nodes = [[] for _ in range(num_comps)]\n",
    "\n",
    "    # Group original nodes into SCC components\n",
    "    for node, cid in comp_id.items():\n",
    "        comp_nodes[cid].append(node)\n",
    "\n",
    "    # Add DAG edges\n",
    "    for u in graph:\n",
    "        cu = comp_id[u]\n",
    "        for v in graph[u]:\n",
    "            cv = comp_id[v]\n",
    "            if cu != cv:\n",
    "                dag[cu].add(cv)\n",
    "\n",
    "    # Convert sets to lists for speed\n",
    "    dag = [list(neigh) for neigh in dag]\n",
    "    return dag, comp_nodes\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# DP over condensed DAG (bitmask for required nodes)\n",
    "def count_paths_scc_dp(graph, start, end, required_nodes):\n",
    "\n",
    "    # ---- Build SCCs ----\n",
    "    comp_id, num_comps = compute_scc(graph)\n",
    "\n",
    "    # Condensed DAG\n",
    "    dag, comp_nodes = build_condensed_dag(graph, comp_id, num_comps)\n",
    "\n",
    "    start_c = comp_id[start]\n",
    "    end_c = comp_id[end]\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Compute reachability to end\n",
    "    rev = [[] for _ in range(num_comps)]\n",
    "    for u in range(num_comps):\n",
    "        for v in dag[u]:\n",
    "            rev[v].append(u)\n",
    "\n",
    "    reachable = [False] * num_comps\n",
    "    reachable[end_c] = True\n",
    "    queue = [end_c]\n",
    "\n",
    "    while queue:\n",
    "        x = queue.pop()\n",
    "        for y in rev[x]:\n",
    "            if not reachable[y]:\n",
    "                reachable[y] = True\n",
    "                queue.append(y)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Map required nodes to required bits by component\n",
    "    required_nodes = [r for r in required_nodes if r in comp_id]\n",
    "    req_bits = {}\n",
    "    for i, r in enumerate(required_nodes):\n",
    "        req_bits[r] = (1 << i)\n",
    "\n",
    "    full_mask = (1 << len(required_nodes)) - 1\n",
    "\n",
    "    # Each component may contain multiple required nodes\n",
    "    comp_required_mask = [0] * num_comps\n",
    "    for node, cid in comp_id.items():\n",
    "        if node in req_bits:\n",
    "            comp_required_mask[cid] |= req_bits[node]\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Topological ordering since DAG\n",
    "    indeg = [0]*num_comps\n",
    "    for u in range(num_comps):\n",
    "        for v in dag[u]:\n",
    "            indeg[v] += 1\n",
    "\n",
    "    topo = []\n",
    "    q = deque()\n",
    "\n",
    "    for i in range(num_comps):\n",
    "        if indeg[i] == 0:\n",
    "            q.append(i)\n",
    "\n",
    "    while q:\n",
    "        x = q.popleft()\n",
    "        topo.append(x)\n",
    "        for y in dag[x]:\n",
    "            indeg[y] -= 1\n",
    "            if indeg[y] == 0:\n",
    "                q.append(y)\n",
    "\n",
    "    dp = [defaultdict(int) for _ in range(num_comps)]\n",
    "    # Start mask\n",
    "    start_mask = comp_required_mask[start_c]\n",
    "    dp[start_c][start_mask] = 1\n",
    "\n",
    "    for u in topo:\n",
    "        if not reachable[u]:\n",
    "            continue  # prune unreachable components\n",
    "        for mask, count in list(dp[u].items()):\n",
    "            for v in dag[u]:\n",
    "                if not reachable[v]:\n",
    "                    continue\n",
    "\n",
    "                new_mask = mask | comp_required_mask[v]\n",
    "                dp[v][new_mask] += count\n",
    "\n",
    "    return dp[end_c][full_mask]\n",
    "\n",
    "\n",
    "with open(\"input.txt\") as f:\n",
    "    inputs = [line.strip() for line in f]\n",
    "\n",
    "graph = parse_graph(inputs)\n",
    "count = count_paths_scc_dp(graph, \"svr\", \"out\", [\"fft\", \"dac\"])\n",
    "\n",
    "print(count)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse6040",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
